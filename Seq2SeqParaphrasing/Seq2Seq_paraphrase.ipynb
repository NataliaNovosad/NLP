{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit memory usage\n",
    "import resource \n",
    "  \n",
    "def limit_memory(maxsize): \n",
    "    if maxsize > 16: \n",
    "        print(\"Max size was set to max 16 GB\")\n",
    "        maxsize = 16\n",
    "    soft, hard = resource.getrlimit(resource.RLIMIT_AS) \n",
    "    maxsize = maxsize * 1024 * 1000000\n",
    "    resource.setrlimit(resource.RLIMIT_AS, (maxsize, hard)) \n",
    "\n",
    "limit_memory(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name):    \n",
    "    with open(file_name, \"r\") as f:\n",
    "        lines = [l.upper().split(\"\\t\") for l in f.read().splitlines()]\n",
    "    df = pd.DataFrame(lines, columns = [\"id\", \"s1\", \"s2\", \"score\"])\n",
    "    df.score = df.score.astype(float)\n",
    "    return df\n",
    "\n",
    "def read_data_train(file_name):    \n",
    "    with open(file_name, \"r\") as f:\n",
    "        lines = [l.upper().split(\"\\t\")[:3] for l in f.read().splitlines()]\n",
    "    df = pd.DataFrame(lines, columns = [\"id\", \"s1\", \"s2\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I decided to use a sample with the size 30000 to speed up the calculations and to fit in memory. In parallel, I run the same notebook in Google Colab [here](https://drive.google.com/file/d/1QgfMsusHv9AeLa0-8DdiFnt8oN4_u_13/view?usp=sharing).  Unfortunatelly the notebook was disconnected from the server, so I did not get the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_name = \"opusparcus_v2/opusparcus_v2/en-test.txt\"\n",
    "train_file_name = \"opusparcus_v2/opusparcus_v2/en-train-100K.txt\"\n",
    "dev_file_name = \"opusparcus_v2/opusparcus_v2/en-dev.txt\"\n",
    "test_data = read_data(test_file_name)\n",
    "train_data = read_data_train(train_file_name).iloc[:30000]\n",
    "dev_data = read_data(dev_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EN-N7</td>\n",
       "      <td>JUMBY NOW WANTS TO BE BORN .</td>\n",
       "      <td>JUMBY WANT BIRTH .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EN-N8</td>\n",
       "      <td>IT WAS A DIFFICULT AND LONG DELIVERY .</td>\n",
       "      <td>THE DELIVERY WAS DIFFICULT AND LONG .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EN-N12</td>\n",
       "      <td>I LIKE TO BE BEAUTIFUL EVERYDAY .</td>\n",
       "      <td>I LIKE TO BE PRETTY EVERYDAY .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EN-N22</td>\n",
       "      <td>BERNADETTE WANTS A PRENUP .</td>\n",
       "      <td>BERNADETTE WANTS TO GET A PRENUP .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EN-N45</td>\n",
       "      <td>DON 'T SAY YOU DON 'T REMEMBER ME .</td>\n",
       "      <td>DON 'T TELL ME YOU DON 'T REMEMBER ME .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                      s1  \\\n",
       "0   EN-N7            JUMBY NOW WANTS TO BE BORN .   \n",
       "1   EN-N8  IT WAS A DIFFICULT AND LONG DELIVERY .   \n",
       "2  EN-N12       I LIKE TO BE BEAUTIFUL EVERYDAY .   \n",
       "3  EN-N22             BERNADETTE WANTS A PRENUP .   \n",
       "4  EN-N45     DON 'T SAY YOU DON 'T REMEMBER ME .   \n",
       "\n",
       "                                        s2  \n",
       "0                       JUMBY WANT BIRTH .  \n",
       "1    THE DELIVERY WAS DIFFICULT AND LONG .  \n",
       "2           I LIKE TO BE PRETTY EVERYDAY .  \n",
       "3       BERNADETTE WANTS TO GET A PRENUP .  \n",
       "4  DON 'T TELL ME YOU DON 'T REMEMBER ME .  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1445, 4), (30000, 3), (1455, 4))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape, train_data.shape, dev_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum lenght in the train dataset = 209\n"
     ]
    }
   ],
   "source": [
    "l1 = train_data.s1.apply(len)\n",
    "l2 = train_data.s2.apply(len)\n",
    "MAX_INPUT_SIZE = max(max(l1), max(l2))\n",
    "print(\"The maximum lenght in the train dataset =\", MAX_INPUT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decided to use only pheases 50-character long to avoid memmory error\n",
    "train_data = train_data[(train_data.s1.apply(len)<=50)&(train_data.s2.apply(len)<=50)]\n",
    "test_data = test_data[(test_data.s1.apply(len)<=50)&(test_data.s2.apply(len)<=50)]\n",
    "dev_data = dev_data[(dev_data.s1.apply(len)<=50)&(dev_data.s2.apply(len)<=50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1402, 4), (29851, 3), (1419, 4))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape, train_data.shape, dev_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum lenght in the train dataset = 50\n"
     ]
    }
   ],
   "source": [
    "l1 = train_data.s1.apply(len)\n",
    "l2 = train_data.s2.apply(len)\n",
    "MAX_INPUT_SIZE = max(max(l1), max(l2))\n",
    "print(\"The maximum lenght in the train dataset =\", MAX_INPUT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = \"s\"\n",
    "END = \"e\"\n",
    "NONE = \"n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character-level data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 128 ms, sys: 2.47 ms, total: 131 ms\n",
      "Wall time: 154 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "MAX_INPUT_SIZE = MAX_INPUT_SIZE + 2\n",
    "\n",
    "def gen_char_seq(s1, s2):\n",
    "    x1 = s1 + NONE*(MAX_INPUT_SIZE-len(s1))\n",
    "    s2_se = START + s2 + NONE*(MAX_INPUT_SIZE-len(s2)-2) + END\n",
    "    return x1, s2_se[:-1], s2_se[1:]\n",
    "\n",
    "def gen_char_seq_data(df):\n",
    "    X1 = []\n",
    "    X2 = []\n",
    "    Y = []\n",
    "    for v in df[[\"s1\", \"s2\"]].values:\n",
    "        # use the first sentence as input and another as output and vise versa\n",
    "        x1,x2,y = gen_char_seq(v[1], v[0])\n",
    "        X1.append(x1)\n",
    "        X2.append(x2)\n",
    "        Y.append(y)\n",
    "        x1,x2,y = gen_char_seq(v[0], v[1])\n",
    "        X1.append(x1)\n",
    "        X2.append(x2)\n",
    "        Y.append(y)\n",
    "    return X1,X2,Y\n",
    "        \n",
    "        \n",
    "char_X1, char_X2, char_Y = gen_char_seq_data(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['JUMBY WANT BIRTH .nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn',\n",
       "  'JUMBY NOW WANTS TO BE BORN .nnnnnnnnnnnnnnnnnnnnnnnn'],\n",
       " ['sJUMBY NOW WANTS TO BE BORN .nnnnnnnnnnnnnnnnnnnnnn',\n",
       "  'sJUMBY WANT BIRTH .nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnn'],\n",
       " ['JUMBY NOW WANTS TO BE BORN .nnnnnnnnnnnnnnnnnnnnnne',\n",
       "  'JUMBY WANT BIRTH .nnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnne'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_X1[0:2], char_X2[0:2], char_Y[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, \"'\": 1, ',': 2, '-': 3, '.': 4, ':': 5, '?': 6, 'A': 7, 'B': 8, 'C': 9, 'D': 10, 'E': 11, 'F': 12, 'G': 13, 'H': 14, 'I': 15, 'J': 16, 'K': 17, 'L': 18, 'M': 19, 'N': 20, 'O': 21, 'P': 22, 'Q': 23, 'R': 24, 'S': 25, 'T': 26, 'U': 27, 'V': 28, 'W': 29, 'X': 30, 'Y': 31, 'Z': 32, 's': 33, 'e': 34, 'n': 35}\n"
     ]
    }
   ],
   "source": [
    "# Map characters to integers\n",
    "# to avoid memory error, I used limmited number of symbols\n",
    "chars = [' ', \"'\", ',', '-', '.',':', '?', 'A', 'B', 'C', 'D', 'E', 'F',\n",
    "       'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S',\n",
    "       'T', 'U', 'V', 'W', 'X', 'Y', 'Z'] + [START, END, NONE] \n",
    "mapping = dict((c, i) for i, c in enumerate(chars))\n",
    "reverse_mapping = dict((c, i) for i, c in mapping.items())\n",
    "\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_map(X_str):\n",
    "    X_int = []\n",
    "    for i in X_str:\n",
    "        X_int.append(list([mapping[char] if char in chars else mapping[NONE] for char in i]))\n",
    "    return np.array(X_int)\n",
    "\n",
    "encoder_input = apply_map(char_X1)\n",
    "dencoder_input = apply_map(char_X2)\n",
    "dencoder_output = apply_map(char_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59702, 52), (59702, 51), (59702, 51))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input.shape, dencoder_input.shape, dencoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.69 s, sys: 408 ms, total: 4.1 s\n",
      "Wall time: 4.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# convert one hot encoding\n",
    "\n",
    "encoder_input_bytes = np.zeros((encoder_input.shape[0], encoder_input.shape[1], len(mapping)),dtype=\"float32\")\n",
    "dencoder_input_bytes = np.zeros((dencoder_input.shape[0], dencoder_input.shape[1], len(mapping)),dtype=\"float32\")\n",
    "dencoder_output_bytes = np.zeros((dencoder_output.shape[0], dencoder_output.shape[1], len(mapping)),dtype=\"float32\")\n",
    "\n",
    "for i,row in enumerate(encoder_input):\n",
    "    for j,number in enumerate(row):\n",
    "        encoder_input_bytes[i,j,number] = 1.0\n",
    "\n",
    "for i,row in enumerate(dencoder_input):\n",
    "    for j,number in enumerate(row):\n",
    "        dencoder_input_bytes[i,j,number] = 1.0\n",
    "\n",
    "for i,row in enumerate(dencoder_output):\n",
    "    for j,number in enumerate(row):\n",
    "        dencoder_output_bytes[i,j,number] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train a model\n",
    "\n",
    "Model structure is based on [this tutorial](https://keras.io/examples/nlp/lstm_seq2seq/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "latent_dim = 128\n",
    "num_encoder_tokens = len(mapping)\n",
    "num_decoder_tokens = len(mapping)\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
    "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
    "\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I trained the model for 30 epochs with 30000 train sample. It took less than hour to finish training. In my Colaboratory notebook the training lasts for 62 epochs with all the data and lasted almost 12 hours before disconnection. The best score in Colab was almost 90%. Here I've got 88%. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "374/374 [==============================] - 79s 211ms/step - loss: 1.2105 - accuracy: 0.6734 - val_loss: 0.9581 - val_accuracy: 0.7358\n",
      "Epoch 2/30\n",
      "374/374 [==============================] - 77s 207ms/step - loss: 0.8487 - accuracy: 0.7516 - val_loss: 0.8031 - val_accuracy: 0.7634\n",
      "Epoch 3/30\n",
      "374/374 [==============================] - 72s 192ms/step - loss: 0.7503 - accuracy: 0.7793 - val_loss: 0.7158 - val_accuracy: 0.7850\n",
      "Epoch 4/30\n",
      "374/374 [==============================] - 80s 214ms/step - loss: 0.6834 - accuracy: 0.7983 - val_loss: 0.6577 - val_accuracy: 0.8017\n",
      "Epoch 5/30\n",
      "374/374 [==============================] - 79s 211ms/step - loss: 0.6341 - accuracy: 0.8121 - val_loss: 0.6073 - val_accuracy: 0.8287\n",
      "Epoch 6/30\n",
      "374/374 [==============================] - 85s 227ms/step - loss: 0.5966 - accuracy: 0.8231 - val_loss: 0.5952 - val_accuracy: 0.8319\n",
      "Epoch 7/30\n",
      "374/374 [==============================] - 84s 223ms/step - loss: 0.5680 - accuracy: 0.8315 - val_loss: 0.5662 - val_accuracy: 0.8337\n",
      "Epoch 8/30\n",
      "374/374 [==============================] - 82s 220ms/step - loss: 0.5447 - accuracy: 0.8387 - val_loss: 0.5463 - val_accuracy: 0.8467\n",
      "Epoch 9/30\n",
      "374/374 [==============================] - 82s 219ms/step - loss: 0.5256 - accuracy: 0.8442 - val_loss: 0.5326 - val_accuracy: 0.8487\n",
      "Epoch 10/30\n",
      "374/374 [==============================] - 79s 211ms/step - loss: 0.5101 - accuracy: 0.8486 - val_loss: 0.5209 - val_accuracy: 0.8496\n",
      "Epoch 11/30\n",
      "374/374 [==============================] - 79s 212ms/step - loss: 0.4968 - accuracy: 0.8528 - val_loss: 0.5224 - val_accuracy: 0.8389\n",
      "Epoch 12/30\n",
      "374/374 [==============================] - 84s 226ms/step - loss: 0.4847 - accuracy: 0.8564 - val_loss: 0.5036 - val_accuracy: 0.8447\n",
      "Epoch 13/30\n",
      "374/374 [==============================] - 78s 209ms/step - loss: 0.4733 - accuracy: 0.8593 - val_loss: 0.5092 - val_accuracy: 0.8460\n",
      "Epoch 14/30\n",
      "374/374 [==============================] - 79s 212ms/step - loss: 0.4643 - accuracy: 0.8625 - val_loss: 0.4888 - val_accuracy: 0.8569\n",
      "Epoch 15/30\n",
      "374/374 [==============================] - 78s 208ms/step - loss: 0.4552 - accuracy: 0.8655 - val_loss: 0.4769 - val_accuracy: 0.8568\n",
      "Epoch 16/30\n",
      "374/374 [==============================] - 83s 221ms/step - loss: 0.4469 - accuracy: 0.8681 - val_loss: 0.4775 - val_accuracy: 0.8509\n",
      "Epoch 17/30\n",
      "374/374 [==============================] - 80s 213ms/step - loss: 0.4391 - accuracy: 0.8705 - val_loss: 0.4914 - val_accuracy: 0.8521\n",
      "Epoch 18/30\n",
      "374/374 [==============================] - 79s 212ms/step - loss: 0.4318 - accuracy: 0.8729 - val_loss: 0.4574 - val_accuracy: 0.8649\n",
      "Epoch 19/30\n",
      "374/374 [==============================] - 79s 211ms/step - loss: 0.4246 - accuracy: 0.8750 - val_loss: 0.4790 - val_accuracy: 0.8549\n",
      "Epoch 20/30\n",
      "374/374 [==============================] - 83s 223ms/step - loss: 0.4184 - accuracy: 0.8769 - val_loss: 0.4416 - val_accuracy: 0.8725\n",
      "Epoch 21/30\n",
      "374/374 [==============================] - 78s 209ms/step - loss: 0.4121 - accuracy: 0.8787 - val_loss: 0.4572 - val_accuracy: 0.8583\n",
      "Epoch 22/30\n",
      "374/374 [==============================] - 81s 216ms/step - loss: 0.4075 - accuracy: 0.8803 - val_loss: 0.4261 - val_accuracy: 0.8795\n",
      "Epoch 23/30\n",
      "374/374 [==============================] - 78s 210ms/step - loss: 0.4014 - accuracy: 0.8792 - val_loss: 0.4456 - val_accuracy: 0.8605\n",
      "Epoch 24/30\n",
      "374/374 [==============================] - 88s 235ms/step - loss: 0.3955 - accuracy: 0.8797 - val_loss: 0.4391 - val_accuracy: 0.8644\n",
      "Epoch 25/30\n",
      "374/374 [==============================] - 88s 235ms/step - loss: 0.3909 - accuracy: 0.8813 - val_loss: 0.4238 - val_accuracy: 0.8771\n",
      "Epoch 26/30\n",
      "374/374 [==============================] - 82s 220ms/step - loss: 0.3868 - accuracy: 0.8830 - val_loss: 0.4233 - val_accuracy: 0.8805\n",
      "Epoch 27/30\n",
      "374/374 [==============================] - 80s 214ms/step - loss: 0.3827 - accuracy: 0.8842 - val_loss: 0.4151 - val_accuracy: 0.8836\n",
      "Epoch 28/30\n",
      "374/374 [==============================] - 82s 219ms/step - loss: 0.3783 - accuracy: 0.8882 - val_loss: 0.4070 - val_accuracy: 0.8848\n",
      "Epoch 29/30\n",
      "374/374 [==============================] - 81s 217ms/step - loss: 0.3746 - accuracy: 0.8915 - val_loss: 0.4018 - val_accuracy: 0.8861\n",
      "Epoch 30/30\n",
      "374/374 [==============================] - 81s 217ms/step - loss: 0.3705 - accuracy: 0.8930 - val_loss: 0.4005 - val_accuracy: 0.8860\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fe74048d880>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128 \n",
    "epochs = 30\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "model.fit(\n",
    "    [encoder_input_bytes, dencoder_input_bytes],\n",
    "    dencoder_output_bytes,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nata/PycharmProjects/UCU/NLP/nlp_env/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /home/nata/PycharmProjects/UCU/NLP/nlp_env/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: s2s/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"s2s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.models.load_model(\"s2s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the encoder and decoder.\n",
    "encoder_inputs = model2.input[0]  # input_1\n",
    "encoder_outputs, state_h_enc, state_c_enc = model2.layers[2].output  # lstm_1\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_inputs = model2.input[1]  # input_2\n",
    "decoder_state_input_h = keras.Input(shape=(latent_dim,), name=\"input_3\")\n",
    "decoder_state_input_c = keras.Input(shape=(latent_dim,), name=\"input_4\")\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_lstm = model2.layers[3]\n",
    "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_states = [state_h_dec, state_c_dec]\n",
    "decoder_dense = model2.layers[4]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = keras.Model(\n",
    "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, mapping[START]] = 1.0\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = \"\"\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        \n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_mapping[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if sampled_char == END or len(decoded_sentence) > MAX_INPUT_SIZE:\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input row: JUMBY NOW WANTS TO BE BORN .\n",
      "True row: JUMBY WANT BIRTH .\n",
      "Predicted row: GET THE RIGHT , DARLING .nnnnnnnnnnnnnnnnnnnnnnnnne\n",
      "CPU times: user 2.71 s, sys: 15.4 ms, total: 2.72 s\n",
      "Wall time: 2.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Input row:\", train_data.iloc[0].s1)\n",
    "print(\"True row:\", train_data.iloc[0].s2)\n",
    "print(\"Predicted row:\", decode_sequence(encoder_input_bytes[0:1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check on all dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_char_X1, dev_char_X2, dev_char_Y = gen_char_seq_data(dev_data)\n",
    "\n",
    "dev_encoder_input = apply_map(dev_char_X1)\n",
    "\n",
    "dev_encoder_input_bytes = np.zeros((dev_encoder_input.shape[0], dev_encoder_input.shape[1], len(mapping)),dtype=\"float32\")\n",
    "\n",
    "for i,row in enumerate(dev_encoder_input):\n",
    "    for j,number in enumerate(row):\n",
    "        dev_encoder_input_bytes[i,j,number] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 31min 34s, sys: 1min 8s, total: 1h 32min 42s\n",
      "Wall time: 1h 30min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dev_true = []\n",
    "dev_preds = []\n",
    "\n",
    "for i, s in enumerate(dev_char_Y):\n",
    "    clean_s = \"\".join([c for c in s if c not in [START, END, NONE]])\n",
    "    dev_true.append(clean_s)\n",
    "    pred_s = decode_sequence(np.array([dev_encoder_input_bytes[i]]))\n",
    "    clean_pred_s = \"\".join([c for c in pred_s if c not in [START, END, NONE]])\n",
    "    dev_preds.append(clean_pred_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('300 HEAVY HORSE ?', \"WE 'VE GOT TO GO .\"),\n",
       " ('WE HAVE NO CHANCE .', 'ANYBODY ON THE ?'),\n",
       " (\"WHEN 'D YOU LAST SEE HIM ?\", 'WHEN WILL HE BE THAT ?'),\n",
       " ('WHEN WAS THE LAST TIME YOU SAW HIM ?', 'WHEN WILL HE BE THAT ?'),\n",
       " ('ANYONE WHO CAN VERIFY THAT ?', 'CAN I TALK TO YOU FOR A MINUTE ?')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(dev_true[:5], dev_preds[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rouge\n",
    "\n",
    "def get_rouge(true, preds):\n",
    "    def prepare_results(p, r, f):\n",
    "        return '\\t{}:\\t{}: {:5.2f}\\t{}: {:5.2f}\\t{}: {:5.2f}'.format(metric, 'P', 100.0 * p, 'R', 100.0 * r, 'F1', 100.0 * f)\n",
    "    \n",
    "    evaluator = rouge.Rouge(metrics=['rouge-l'],\n",
    "                           max_n=3,\n",
    "                           limit_length=True,\n",
    "                           length_limit=100,\n",
    "                           length_limit_type='words',\n",
    "                           apply_avg=True,\n",
    "                           apply_best=False,\n",
    "                           alpha=0.5, # Default F1_score\n",
    "                           weight_factor=1.2,\n",
    "                           stemming=True)\n",
    "\n",
    "    scores = evaluator.get_scores(true, preds)\n",
    "    for metric, results in sorted(scores.items(), key=lambda x: x[0]):\n",
    "        print(prepare_results(results['p'], results['r'], results['f']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\trouge-l:\tP: 18.37\tR: 18.69\tF1: 18.20\n"
     ]
    }
   ],
   "source": [
    "get_rouge(dev_true, dev_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check on 3-4 scored dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_char_X1, dev_char_X2, dev_char_Y = gen_char_seq_data(dev_data[(dev_data.score>3)&(dev_data.score<=4)])\n",
    "\n",
    "dev_encoder_input = apply_map(dev_char_X1)\n",
    "\n",
    "dev_encoder_input_bytes = np.zeros((dev_encoder_input.shape[0], dev_encoder_input.shape[1], len(mapping)),dtype=\"float32\")\n",
    "\n",
    "for i,row in enumerate(dev_encoder_input):\n",
    "    for j,number in enumerate(row):\n",
    "        dev_encoder_input_bytes[i,j,number] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56min 24s, sys: 48.8 s, total: 57min 13s\n",
      "Wall time: 57min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dev_true4 = []\n",
    "dev_preds4 = []\n",
    "\n",
    "for i, s in enumerate(dev_char_Y):\n",
    "    clean_s = \"\".join([c for c in s if c not in [START, END, NONE]])\n",
    "    dev_true4.append(clean_s)\n",
    "    pred_s = decode_sequence(np.array([dev_encoder_input_bytes[i]]))\n",
    "    clean_pred_s = \"\".join([c for c in pred_s if c not in [START, END, NONE]])\n",
    "    dev_preds4.append(clean_pred_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"WHEN 'D YOU LAST SEE HIM ?\", 'WHEN WILL HE BE THAT ?'),\n",
       " ('WHEN WAS THE LAST TIME YOU SAW HIM ?', 'WHEN WILL HE BE THAT ?'),\n",
       " ('ANYONE WHO CAN VERIFY THAT ?', 'CAN I TALK TO YOU FOR A MINUTE ?'),\n",
       " ('CAN ANYONE CORROBORATE THAT ?', \"ANYTHING THE BEGIN 'S TO THAT ?\"),\n",
       " (\"NOTHING 'S CHANGED .\", \"IT 'S NOTHING TO SAY .\")]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(dev_true4[:5], dev_preds4[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\trouge-l:\tP: 21.91\tR: 22.09\tF1: 21.64\n"
     ]
    }
   ],
   "source": [
    "get_rouge(dev_true4, dev_preds4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the model is not good enough to say it works fine. The phases generated by NN contain real words, but sometimes they do not have sense. Also, the connection with input sentence is poor. But I trained a relatively small model, only for 30 epochs and on a train sample of 30000. I expect that if I trained larger model for more time and with all the data, the results would be better. Also I checked Rouge-L score on all the dev data and only with labeled score 3-4. As a result, the model perform better on better data: the Rouge-L is bigger with data labeled 3-4."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
